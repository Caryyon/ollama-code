{
    "name": "olc",
    "version": "0.1.0",
    "description": "A FLOSS alternative to Claude Code using Ollama for local LLM inference",
    "main": "src/index.js",
    "bin": {
        "olc": "./bin/ollama-code.js"
    },
    "scripts": {
        "start": "node --experimental-json-modules bin/ollama-code.js",
        "lint": "eslint src",
        "test": "jest"
    },
    "engines": {
        "node": ">=18.0.0"
    },
    "keywords": [
        "ollama",
        "ai",
        "cli",
        "code",
        "assistant",
        "development",
        "local-llm"
    ],
    "author": "",
    "license": "MIT",
    "dependencies": {
        "chalk": "^5.3.0",
        "commander": "^11.1.0",
        "conf": "^12.0.0",
        "dotenv": "^16.3.1",
        "globby": "^14.0.0",
        "inquirer": "^9.2.12",
        "marked": "^9.1.5",
        "marked-terminal": "^6.1.0",
        "node-fetch": "^3.3.2",
        "ora": "^7.0.1",
        "simple-git": "^3.20.0",
        "tiktoken": "^1.0.10"
    },
    "devDependencies": {
        "eslint": "^8.54.0",
        "jest": "^29.7.0"
    },
    "type": "module"
}